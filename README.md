#Deep learning
Using Keras for building neural networks

create a neural network with two hidden layers of 64 and 32 neurons respectively. The activation function for these layers is ReLU. The output layer has 1 neuron (since we're doing regression) and no activation function. The loss function is mean squared error and the optimizer is Adam.

This is a simple neural network. Depending on your specific use case and the complexity of your data, you may need a more complex network. For example, you might need more layers, different types of layers (e.g., convolutional or recurrent layers), dropout for regularization, etc.

In addition, you might need to tune the hyperparameters of your network to get the best performance. This can be done manually, or by using techniques such as grid search or randomized search.

You need to have TensorFlow installed in your environment to run this code.
